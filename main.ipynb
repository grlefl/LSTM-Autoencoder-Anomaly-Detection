{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Coding Resources**\n",
    "- https://github.com/lestercardoz11/SP-500-index-anomaly-detection - (S&P 500 anomaly detection repository)\n",
    "- https://curiousily.com/posts/anomaly-detection-in-time-series-with-lstms-using-keras-in-python/ - (S&P 500 anomaly detection tutorial)\n",
    "- https://curiousily.com/posts/time-series-anomaly-detection-using-lstm-autoencoder-with-pytorch-in-python/ - (pytorch LSTM implementation tutorial)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "be35abd1b7433c7c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pyplot \u001B[38;5;28;01mas\u001B[39;00m plt\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T17:26:04.033343Z",
     "start_time": "2024-04-28T17:26:04.030020Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "5d6d8ed80dc95f26",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "**S&P500 Daily Prices 1986-2018**\n",
    "--description--"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "217d5aa1ded73fb8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "filepath = './data/spx.csv'\n",
    "df = pd.read_csv(filepath)\n",
    "print(df.shape)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T17:26:04.068203Z",
     "start_time": "2024-04-28T17:26:04.054345Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "6dbef7e29b103f86",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Visualize Data**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "759b0b2d525c94ed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'], format='%d-%b-%y')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# plot time series data\n",
    "ax1.plot(df['date'], df['close'], color='purple')\n",
    "ax1.set_xlabel('Year')\n",
    "ax1.set_ylabel('Closing Price')\n",
    "ax1.set_title('S&P 500 Closing Price History')\n",
    "ax1.grid(True)\n",
    "\n",
    "# plot histogram\n",
    "ax2.hist(df['close'], bins=30, color='purple', edgecolor='purple', alpha=0.4, histtype='bar')\n",
    "ax2.set_title('Histogram of Closing Prices')\n",
    "ax2.set_xlabel('Closing Price')\n",
    "ax2.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T17:26:04.289331Z",
     "start_time": "2024-04-28T17:26:04.073195Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "87fe7041e94a397f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Split & Standardize Data**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "13466318b55b3ccb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# split data\n",
    "train_size = int(len(df) * 0.95)\n",
    "test_size = len(df) - train_size\n",
    "train, test = df.iloc[0:train_size], df.iloc[train_size:len(df)]\n",
    "print(train.shape, test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# scalar fit to training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train[['close']])\n",
    "\n",
    "# standardize train and test data\n",
    "train.loc[:, 'close'] = scaler.transform(train[['close']])\n",
    "test.loc[:, 'close'] = scaler.transform(test[['close']])\n",
    "print(\"Train Mean:\", train['close'].mean(), \"Train Standard Deviation:\", train['close'].std())\n",
    "print(\"Test Mean:\", test['close'].mean(), \"Test Standard Deviation:\", test['close'].std())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "2e12a6e9c6b24d3d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Prepare Dataset**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**LSTM Autoencoder**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "cebaa09d56b97933"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, seq_len, n_features, embedding_dim=64):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.n_features = n_features\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = embedding_dim, 2 * embedding_dim\n",
    "\n",
    "        self.rnn1 = nn.LSTM(\n",
    "            input_size=n_features,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.rnn2 = nn.LSTM(\n",
    "            input_size=self.hidden_dim,\n",
    "            hidden_size=embedding_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape((1, self.seq_len, self.n_features))\n",
    "        x, (_, _) = self.rnn1(x)\n",
    "        x, (hidden_n, _) = self.rnn2(x)\n",
    "        return hidden_n.reshape((self.n_features, self.embedding_dim))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T17:39:44.353764Z",
     "start_time": "2024-04-28T17:39:44.307863Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "6b9d31bc208306",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, seq_len, input_dim=64, n_features=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.input_dim = input_dim\n",
    "        self.n_features = n_features\n",
    "        self.hidden_dim = 2 * input_dim, n_features\n",
    "\n",
    "        self.rnn1 = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=input_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.rnn2 = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(self.hidden_dim, n_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.repeat(self.seq_len, self.n_features)\n",
    "        x = x.reshape((self.n_features, self.seq_len, self.input_dim))\n",
    "        x, (hidden_n, cell_n) = self.rnn1(x)\n",
    "        x, (hidden_n, cell_n) = self.rnn2(x)\n",
    "        x = x.reshape((self.seq_len, self.hidden_dim))\n",
    "\n",
    "        return self.output_layer(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LSTMAutoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self, device, seq_len, n_features, embedding_dim=64):\n",
    "        super(LSTMAutoencoder, self).__init__()\n",
    "        self.encoder = Encoder(seq_len, n_features, embedding_dim).to(device)\n",
    "        self.decoder = Decoder(seq_len, embedding_dim, n_features).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Training Loop**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "c520f90696134577"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_model(model, device, train_dataset, optimizer, criterion):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "\n",
    "    for seq_true in train_dataset:\n",
    "        optimizer.zero_grad()\n",
    "        seq_true = seq_true.to(device)\n",
    "        seq_pred = model(seq_true)\n",
    "        loss = criterion(seq_pred, seq_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    return train_losses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def validate_model(model, device, val_dataset, criterion):\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq_true in val_dataset:\n",
    "            seq_true = seq_true.to(device)\n",
    "            seq_pred = model(seq_true)\n",
    "            loss = criterion(seq_pred, seq_true)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "    return val_losses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_model_full(model, train_dataset, val_dataset, optimizer, criterion, n_epochs):\n",
    "    history = {'train': [], 'val': []}\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 10000.0\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_losses = train_model(model, train_dataset, optimizer, criterion)\n",
    "        val_losses = validate_model(model, val_dataset, criterion)\n",
    "\n",
    "        train_loss = np.mean(train_losses)\n",
    "        val_loss = np.mean(val_losses)\n",
    "        history['train'].append(train_loss)\n",
    "        history['val'].append(val_loss)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print(f'Epoch {epoch}: train loss {train_loss}, val loss {val_loss}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model.eval(), history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Training Evaluation**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "61f29268b175c2a1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = LSTMAutoencoder(seq_len, n_features, 128, criterion)\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "df81a20aabb29caf",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Testing Evaluation**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}